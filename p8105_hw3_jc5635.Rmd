---
title: "Homework 3"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE,
                      warning = FALSE,
                      out.width = "100%")

library(tidyverse)
library(ggridges)
library(patchwork)
```

## Problem 1

```{r initial}
library(p8105.datasets)
data("instacart")

head(instacart, 5)
```

The `instacart` dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns, such as `order_id`, `product_id`, `user_id`, `order_number`, and `product_name`.

```{r insta_orders}
insta_orders = instacart %>%
  mutate(aisle = as.factor(aisle)) %>%
  group_by(aisle) %>%
  summarise(order_count = n_distinct(order_id)) %>%
  arrange(desc(order_count))

head(insta_orders, 5)
```

There are `r instacart %>% select(aisle_id) %>% n_distinct` distinct aisles; `fresh fruits` and `fresh vegetables` are the aisles with the highest order counts.

```{r insta_plot}
insta_orders %>%
  filter(order_count > 10000) %>%
  mutate(aisle = fct_reorder(aisle, order_count, .desc = TRUE)) %>%
  ggplot(aes(x = aisle, y = order_count)) +
  geom_point() +
  labs(
    title = "Order counts by aisle",
    x = "Aisle",
    y = "Number of orders",
    caption = "Source: Instacart"
  ) +
  theme(plot.title = element_text(hjust = .5),
        axis.text.x = element_text(angle = 45, hjust = 1))
```

`paper goods` and `canned jarred vegetables` are the least popular aisles.

```{r insta_pop_items}
instacart %>%
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  mutate(product_name = as.factor(product_name)) %>%
  group_by(aisle, product_name) %>%
  summarise(order_count = n_distinct(order_id)) %>%
  mutate(rank = min_rank(desc(order_count))) %>%
  filter(rank < 4) %>%
  arrange(aisle, rank) %>%
  select(-rank) %>%
  knitr::kable()
```

The most popular item in `packaged vegetables fruits` is `Organic Baby Spinach`.

```{r insta_prod_order_time}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarise(mean_hr = mean(order_hour_of_day)) %>%
  pivot_wider(names_from = product_name,
              values_from = mean_hr) %>%
  knitr::kable(digits = 1)
```
    
On average, Coffee Ice Cream orders tend to be placed after noon and before 4pm, whereas Pink Lady Apples orders tend to be placed between 11am and 3pm.

## Problem 2

```{r accel_tidy}
accel_long = read_csv(file = "data/accel_data.csv") %>%
  janitor::clean_names() %>%
  mutate(day = factor(day, c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))) %>%
  pivot_longer(activity_1:activity_1440,
               names_to = "minute",
               names_prefix = "activity_",
               values_to = "activity_meas_minute") %>%
  mutate(day_type = ifelse(day == "Saturday" | day == "Sunday", "Weekend", "Weekday"),
         day_type = factor(day_type),
         minute = as.numeric(minute)) %>%
  arrange(week, day_id, day, minute)

head(accel_long, 10)
```

We import and tidy the dataset (i.e. `accel_long`) by setting `day` as a factor variable, pivoting the `activity_*` variables to long format, adding a `day_type` variable to distinguish weekdays and weekend days from one another, and defining `minute` as a numeric variable, among other cleaning steps. The resulting dataset contains `r nrow(accel_long)` rows and `r ncol(accel_long)` fields, i.e. temporal variables (e.g. `week`, `day`, `minute`, and `day_type`) and activity counts by minute, as denoted by `activity_meas_minute`.

```{r accel_summary}
accel_long %>%
  group_by(week, day) %>%
  summarise(activity_meas_day = sum(activity_meas_minute)) %>%
  pivot_wider(names_from = day,
              values_from = activity_meas_day) %>%
  janitor::adorn_totals() %>%
  knitr::kable()

# note: activity counts for Saturday in weeks 4 and 5 are 1440 each (i.e. number of minutes in a day; may merit further investigation) 
```

Total daily activity counts for the full five-week data collection period are highest for Wednesday, Thursday, and Friday (2129772, 2091150.6, and 2291710.6, respectively), and lowest for Saturday (1369237).

```{r accel_plot}
ggplot(accel_long, aes(x = minute, y = activity_meas_minute, color = day)) +
  geom_smooth(se = FALSE, alpha = 1, size = 1) + 
  scale_x_continuous(
  breaks = c(120, 240, 360, 480, 600, 720, 840, 960, 1080, 1200, 1320, 1440),
  labels = c("2", "4", "6", "8", "10", "12", "14", "16", "18", "20", "22", "24")
) +
  labs(
    title = "24-hour activity time course for a CHF patient",
    x = "Hour of the day (0 = midnight)",
    y = "Activity counts (LOESS-smoothed)",
    caption = "Source: CUMC"
  ) +
  viridis::scale_color_viridis(
    name = "Day",
    discrete = TRUE
  ) + theme(legend.position = "bottom",
            plot.title = element_text(hjust = .5))
```

The plot above displays 24-hour (LOESS-smoothed) curves for activity counts for each day of the week. For the individual in question, average activity counts appear to fall in or near the 300 to 450 range between 9am and 4pm on weekdays; during the same period of the day, average activity counts trend below this range on Saturdays and exceed this range substantially on Sundays, with the Sunday average peaking above 600 before 11am. The LOESS-smoothed curve for activity counts on Friday rises above 450 around 7pm and peaks above 800 around 9pm, similarly suggesting a period of heightened activity.

## Problem 3

```{r noaa_initial}
library(p8105.datasets)
data("ny_noaa")

skimr::skim(ny_noaa)
```

We first import and review the `ny_noaa` dataset. The data contains `r nrow(ny_noaa)` rows and `r ncol(ny_noaa)` fields, including an `id` variable denoting weather station, a `date` variable for the observation date, and several weather measures (e.g. `snow` for snowfall, `tmax` for maximum temperature, and `tmin` for minimum temperature). There are no missing values on `id` or `date`. `tmax` and `tmin` each contain data on only 56 percent of observations, while the `snwd`, `snow`, and `prcp` variables exhibit higher rates of data completeness (77 percent, 85 percent, and 94 percent, respectively). 

```{r noaa_tidy}
noaa_clean = ny_noaa %>%
  separate(date, into = c("year", "month", "day"), sep = "-", convert = TRUE) %>%
  mutate(tmax_c = as.integer(tmax) / 10, # convert tenths of C to C
         tmin_c = as.integer(tmin) / 10, # convert tenths of C to C
         prcp_cm = prcp / 100, # convert tenths of mm to cm
         snow_cm = snow / 10, # convert mm to cm 
         snwd_cm = snwd / 10) %>% # convert mm to cm 
  rename(snow_mm = snow) %>%
  select(-c(5, 7:9)) %>%
  relocate(snow_mm, .after = prcp_cm)

head(noaa_clean, 10)
```

We proceed to tidy the data by disaggregating `date` into `year`, `month`, and `day` variables; converting units on `tmax` and `tmin` to degrees Celsius; converting units on `prcp`, `snow`, and `snwd` to centimeters; and relabeling variables as necessary, among other cleaning steps.

```{r}
noaa_clean %>%
  group_by(snow_mm) %>%
  summarise(values_count = n()) %>%
  arrange(desc(values_count)) %>%
  head(5)

noaa_clean %>%
  group_by(month) %>%
  summarise(mean_snow_mm = mean(snow_mm, na.rm = TRUE))
```

`0` is the most commonly observed value on `snow_mm` (i.e. the original variable `snow`, renamed), recorded in 2008508 observations, as there is minimal snowfall observed during certain months of the year; in fact, average snowfall (in millimeters) is 0.002 or less in June, July, August, and September. `NA` is the second most commonly observed value on `snow_mm`, recorded in 381221 observations, likely due to stations not collecting data on snowfall (among other fields), as noted in the available documentation for the NOAA dataset.

```{r noaa_two_panel_plot_i}
noaa_clean %>%
  filter(month %in% c(1, 7)) %>%
  mutate(month = ifelse(test = month == 1, "January", "July")) %>%
  group_by(id, year, month) %>% 
  summarise(tmax_avg = mean(tmax_c)) %>%
  ggplot(aes(x = year, y = tmax_avg, color = id)) +
  geom_point(alpha = .5) +
  geom_line() +
  facet_grid(~month) +
  labs(
    title = "Average maximum temperatures in January and July, across years and by station",
    x = "Year",
    y = "Average maximum temperature (in degrees Celsius)",
    caption = "Source: NOAA"
  ) +
  viridis::scale_fill_viridis(discrete = TRUE) +
  theme(legend.position = "none",
            plot.title = element_text(hjust = .5))
```

Average maximum temperatures by station in January, as shown in the above plot, have tended to fall within the -10 to 10 degrees Celsius range across years, with some outliers below -10 degrees Celsius recorded in the early 1980s, the mid-1990s, and the mid-aughts. Average maximum temperatures by station in July have tended to fall within the 20 to 35 degrees Celsius range across years, with a handful of outliers below 20 degrees Celsius recorded in the 1980s and the aughts. The highest average maximum temperature in July for any station appears to have been recorded in 2010.

```{r noaa_two_panel_plot_ii, fig.width = 8, fig.asp = 1.8}
tmax_v_tmin = noaa_clean %>%
  ggplot(aes(x = tmin_c, y = tmax_c)) +
  geom_hex(size = .5) +
  labs(
    title = "Average maximum temperatures vs. average minimum temperatures",
    x = "Average minimum temperature (in degrees Celsius)",
    y = "Average maximum temperature (in degrees Celsius)",
    caption = "Source: NOAA"
  ) +
    theme(plot.title = element_text(hjust = .5))

snow_dist = noaa_clean %>%
  filter(snow_mm > 0 & snow_mm < 100) %>%
  mutate(year = as.factor(year)) %>%
  ggplot(aes(x = snow_mm, y = year)) +
  geom_density_ridges(scale = .8) +
  labs(
    title = "Distributions of snowfalls above 0 millimeters and below 100 millimeters, by year",
    x = "Snowfall (in millimeters)",
    y = "Year",
    caption = "Source: NOAA"
  ) +
    theme(plot.title = element_text(hjust = .5))
# note: uses original units on snow, per 10/12 instruction
  
tmax_v_tmin / snow_dist
```

The first panel (i.e. hexagonal heatmap) appears to show a positive relationship between average minimum temperatures and average maximum temperatures by station. The second panel (i.e. ridge plot) suggests some consistency in overall distribution patterns for snowfall across years, albeit with less pronounced concentrations of snowfalls above 40 millimeters in the latter years.
